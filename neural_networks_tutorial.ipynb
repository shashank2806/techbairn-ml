{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Neural Networks\n",
    "===============\n",
    "\n",
    "Neural networks can be constructed using the ``torch.nn`` package.\n",
    "\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or\n",
    "  weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:\n",
    "  ``weight = weight - learning_rate * gradient``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available. Training on CPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if train_on_gpu:\n",
    "    print('CUDA is available. Training on GPU ...')\n",
    "else:\n",
    "    print('CUDA not available. Training on CPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "We are using MINIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network\n",
    "------------------\n",
    "\n",
    "Let’s define this network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = nn.LogSoftmax(dim=1)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU if available\n",
    "if train_on_gpu:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss Function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer \n",
    "from torch import optim\n",
    "optimizer =  optim.SGD(net.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "* Make a forward pass through the network\n",
    "* Use the network output to calculate the loss\n",
    "* Perform a backward pass through the network with loss.backward() to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15..  Training Loss: 2.104..  Test Loss: 1.629..  Test Accuracy: 0.617\n",
      "Epoch: 2/15..  Training Loss: 1.013..  Test Loss: 0.644..  Test Accuracy: 0.830\n",
      "Epoch: 3/15..  Training Loss: 0.544..  Test Loss: 0.456..  Test Accuracy: 0.874\n",
      "Epoch: 4/15..  Training Loss: 0.433..  Test Loss: 0.388..  Test Accuracy: 0.890\n",
      "Epoch: 5/15..  Training Loss: 0.384..  Test Loss: 0.354..  Test Accuracy: 0.898\n",
      "Epoch: 6/15..  Training Loss: 0.356..  Test Loss: 0.330..  Test Accuracy: 0.905\n",
      "Epoch: 7/15..  Training Loss: 0.335..  Test Loss: 0.315..  Test Accuracy: 0.908\n",
      "Epoch: 8/15..  Training Loss: 0.318..  Test Loss: 0.302..  Test Accuracy: 0.913\n",
      "Epoch: 9/15..  Training Loss: 0.305..  Test Loss: 0.290..  Test Accuracy: 0.918\n",
      "Epoch: 10/15..  Training Loss: 0.293..  Test Loss: 0.278..  Test Accuracy: 0.921\n",
      "Epoch: 11/15..  Training Loss: 0.282..  Test Loss: 0.270..  Test Accuracy: 0.922\n",
      "Epoch: 12/15..  Training Loss: 0.272..  Test Loss: 0.262..  Test Accuracy: 0.925\n",
      "Epoch: 13/15..  Training Loss: 0.263..  Test Loss: 0.252..  Test Accuracy: 0.929\n",
      "Epoch: 14/15..  Training Loss: 0.255..  Test Loss: 0.244..  Test Accuracy: 0.932\n",
      "Epoch: 15/15..  Training Loss: 0.246..  Test Loss: 0.242..  Test Accuracy: 0.931\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    net.train()\n",
    "    for images, labels in trainloader:\n",
    "        # move tensors to GPU is CUDA is available\n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        # Flatten Image\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # Clear the gradeints\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass, get our logits\n",
    "        log_ps = net(images)\n",
    "        # Calculate the loss with the logits and the labels\n",
    "        loss = criterion(log_ps, labels)\n",
    "        # Calculate the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                # move tensors to GPU is CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "                # Flatten Image\n",
    "                images = images.view(images.shape[0], -1)\n",
    "                log_ps = net(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        # print training/test statistics\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted number is: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "img = images[idx].view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "ps = torch.exp(net(img))\n",
    "print(f'predicted number is: {int(torch.argmax(ps))}')\n",
    "plt.imshow(images[idx].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2010e-05, 2.8259e-07, 1.5704e-04, 9.9864e-01, 4.2095e-07, 8.8162e-04,\n",
       "         1.7534e-10, 1.3995e-04, 1.3704e-04, 3.3386e-05]],\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "cnn_net = CNN()\n",
    "print(cnn_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 400], m2: [576 x 120] at /opt/conda/conda-bld/pytorch_1573049308701/work/aten/src/TH/generic/THTensorMath.cpp:197",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8091e405980b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Forward pass, get our logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlog_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Calculate the loss with the logits and the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-a65042a68561>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 400], m2: [576 x 120] at /opt/conda/conda-bld/pytorch_1573049308701/work/aten/src/TH/generic/THTensorMath.cpp:197"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    cnn_net.train()\n",
    "    for images, labels in trainloader:\n",
    "        # move tensors to GPU is CUDA is available\n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        # Flatten Image\n",
    "#         images = images.view(images.shape[0], -1)\n",
    "        # Clear the gradeints\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass, get our logits\n",
    "        log_ps = cnn_net(images)\n",
    "        # Calculate the loss with the logits and the labels\n",
    "        loss = criterion(log_ps, labels)\n",
    "        # Calculate the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                # move tensors to GPU is CUDA is available\n",
    "                if train_on_gpu:\n",
    "                    images, labels = images.cuda(), labels.cuda()\n",
    "                # Flatten Image\n",
    "#                 images = images.view(images.shape[0], -1)\n",
    "                log_ps = cnn_net(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "        # print training/test statistics\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
